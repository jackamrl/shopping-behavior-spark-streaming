# Dashboard Streamlit - Shopping Behavior Analytics

Dashboard de visualisation en temps r√©el des donn√©es depuis BigQuery pour le projet Spark Streaming.

## üéØ Fonctionnalit√©s

- üìä **M√©triques en temps r√©el** : Nombre de commandes, revenus, panier moyen, note moyenne
- üìà **Visualisations interactives** :
  - Vue d'ensemble avec graphiques temporels
  - Analyse par tranche d'√¢ge
  - Analyse par genre
  - Analyse par localisation
  - Analyses combin√©es (√¢ge √ó genre √ó cat√©gorie)
- üîÑ **Actualisation automatique** : Mise √† jour p√©riodique des donn√©es
- üé® **Interface moderne** : Utilise Plotly pour des graphiques interactifs

## üìã Pr√©requis

- Python 3.8+
- Acc√®s √† BigQuery (project ID: `spark-streaming-483317`)
- Credentials GCP configur√©s

## üöÄ Installation

1. **Installer les d√©pendances** :

```bash
cd streamlit
pip install -r requirements.txt
```

2. **Configurer les variables d'environnement** :

```bash
# Copier le fichier d'exemple
cp .env.example .env

# √âditer .env avec vos valeurs
# Ou exporter les variables directement :
export GCP_PROJECT_ID=spark-streaming-483317
export BIGQUERY_DATASET=shopping
export BIGQUERY_TABLE=orders
```

3. **Configurer l'authentification GCP** :

**Option 1 : Application Default Credentials (recommand√© pour Cloud Run/GCP)**

```bash
gcloud auth application-default login
```

**Option 2 : Service Account Key (pour d√©veloppement local)**

```bash
# T√©l√©charger le fichier JSON du Service Account depuis GCP Console
# Exporter le chemin :
export GOOGLE_APPLICATION_CREDENTIALS="path/to/service-account-key.json"
```

## ‚ñ∂Ô∏è Utilisation

### Lancement local

```bash
streamlit run streamlit_app.py
```

Le dashboard sera accessible √† l'adresse : `http://localhost:8501`

### D√©ploiement sur Cloud Run (gratuit jusqu'√† 2M requ√™tes/mois)

1. **Cr√©er un Dockerfile** :

```dockerfile
FROM python:3.11-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY streamlit_app.py .

EXPOSE 8501

HEALTHCHECK CMD curl --fail http://localhost:8501/_stcore/health

ENTRYPOINT ["streamlit", "run", "streamlit_app.py", "--server.port=8501", "--server.address=0.0.0.0"]
```

2. **D√©ployer sur Cloud Run** :

```bash
# Build et d√©ployer
gcloud run deploy shopping-dashboard \
  --source . \
  --platform managed \
  --region europe-west1 \
  --allow-unauthenticated \
  --set-env-vars GCP_PROJECT_ID=spark-streaming-483317,BIGQUERY_DATASET=shopping
```

### D√©ploiement sur Streamlit Cloud (gratuit)

1. Pousser le code sur GitHub
2. Aller sur [streamlit.io/cloud](https://streamlit.io/cloud)
3. Connecter votre repository
4. Configurer les secrets dans Streamlit Cloud :
   - `GOOGLE_APPLICATION_CREDENTIALS` (contenu du fichier JSON du Service Account)

## üìä Vues BigQuery utilis√©es

Le dashboard utilise les vues suivantes (cr√©√©es via `bigquery_views.sql`) :

- `v_age_preferences` : Pr√©f√©rences par tranche d'√¢ge
- `v_gender_preferences` : Pr√©f√©rences par genre
- `v_location_preferences` : Pr√©f√©rences par localisation
- `v_age_gender_category` : Analyse combin√©e √¢ge √ó genre √ó cat√©gorie

Si ces vues n'existent pas encore, cr√©ez-les en ex√©cutant `bigquery_views.sql` dans BigQuery.

## ‚öôÔ∏è Configuration

### Variables d'environnement

| Variable | Description | D√©faut |
|----------|-------------|--------|
| `GCP_PROJECT_ID` | ID du projet GCP | `spark-streaming-483317` |
| `BIGQUERY_DATASET` | Nom du dataset BigQuery | `shopping` |
| `BIGQUERY_TABLE` | Nom de la table BigQuery | `orders` |
| `GOOGLE_APPLICATION_CREDENTIALS` | Chemin vers le fichier de credentials (optionnel) | - |

### Param√®tres dans l'interface

- **Actualisation automatique** : Active/d√©sactive le rafra√Æchissement automatique
- **Intervalle** : Fr√©quence de mise √† jour (5-60 secondes)
- **Filtres** : Filtrage par cat√©gorie et localisation dans le tableau des commandes

## üîç D√©pannage

### Erreur d'authentification

```
Error: Could not automatically determine credentials
```

**Solution** : Configurez les credentials GCP :
```bash
gcloud auth application-default login
```

### Aucune donn√©e affich√©e

- V√©rifiez que le Consumer Spark a trait√© des fichiers
- V√©rifiez que les donn√©es existent dans BigQuery :
  ```bash
  bq query --use_legacy_sql=false "SELECT COUNT(*) FROM \`spark-streaming-483317.shopping.orders\`"
  ```

### Vues BigQuery manquantes

Si vous voyez des avertissements sur les vues manquantes :
1. Ex√©cutez `bigquery_views.sql` dans BigQuery Console
2. Ou modifiez le dataset dans `.env` si vous utilisez un dataset diff√©rent

## üìù Notes

- Le cache des donn√©es est configur√© avec un TTL (Time To Live) pour r√©duire les appels BigQuery
- Les requ√™tes utilisent les vues analytiques pour optimiser les performances
- Le dashboard affiche les derni√®res 10 000 commandes par d√©faut (configurable dans le code)

## üÜò Support

Pour toute question ou probl√®me, consultez :
- Documentation BigQuery : https://cloud.google.com/bigquery/docs
- Documentation Streamlit : https://docs.streamlit.io

