#!/bin/bash
# Script bash pour d√©tecter automatiquement les ressources existantes
# et mettre √† jour les variables use_existing_* dans terraform.tfvars

set -e

PROJECT_ID="${1:-spark-streaming-483317}"
ENVIRONMENT="${2:-dev}"
TF_VARS_FILE="${3:-environments/dev/terraform.tfvars}"

echo "üîç D√©tection automatique des ressources existantes..."
echo "Projet: $PROJECT_ID"
echo "Environnement: $ENVIRONMENT"
echo ""

# Fonction pour v√©rifier si un Service Account existe
check_service_account() {
    local account_id=$1
    local project=$2
    gcloud iam service-accounts describe "${account_id}@${project}.iam.gserviceaccount.com" \
        --project="$project" >/dev/null 2>&1
    return $?
}

# Fonction pour v√©rifier si un bucket existe
check_bucket() {
    local bucket_name=$1
    local project=$2
    # Utiliser gsutil stat qui est plus fiable pour v√©rifier l'existence
    # Si le bucket existe mais qu'on n'a pas les permissions, on essaie aussi gsutil ls -b
    if gsutil stat -p "$project" "gs://$bucket_name" >/dev/null 2>&1; then
        return 0
    fi
    # Fallback: essayer de lister le bucket (peut √©chouer si pas de permissions mais bucket existe)
    if gsutil ls -b -p "$project" "gs://$bucket_name" >/dev/null 2>&1; then
        return 0
    fi
    # Dernier essai: v√©rifier via gcloud storage buckets describe
    if gcloud storage buckets describe "gs://$bucket_name" --project="$project" >/dev/null 2>&1; then
        return 0
    fi
    return 1
}

# Fonction pour v√©rifier si un dataset BigQuery existe
check_dataset() {
    local dataset_id=$1
    local project=$2
    bq show --project_id="$project" "${project}:${dataset_id}" >/dev/null 2>&1
    return $?
}

# D√©tection des Service Accounts
echo "üìã V√©rification des Service Accounts..."
if check_service_account "spark-dataproc-$ENVIRONMENT" "$PROJECT_ID" && \
   check_service_account "spark-consumer-$ENVIRONMENT" "$PROJECT_ID"; then
    echo "  ‚úÖ Service Accounts existent"
    USE_EXISTING_SERVICE_ACCOUNTS="true"
else
    echo "  ‚ùå Service Accounts n'existent pas"
    USE_EXISTING_SERVICE_ACCOUNTS="false"
fi

# D√©tection des buckets
echo "üì¶ V√©rification des buckets GCS..."
PIPELINE_NAME="spark-streaming-pipeline"
BUCKET_PREFIX="${PIPELINE_NAME}-${ENVIRONMENT}-$(echo $PROJECT_ID | tr '.' '-')"

# V√©rifier chaque bucket individuellement pour un meilleur debugging
DATA_BUCKET="${BUCKET_PREFIX}-data"
CHECKPOINT_BUCKET="${BUCKET_PREFIX}-checkpoints"
ARTIFACTS_BUCKET="${BUCKET_PREFIX}-artifacts"

echo "  üîç V√©rification: gs://${DATA_BUCKET}"
DATA_EXISTS=$(check_bucket "$DATA_BUCKET" "$PROJECT_ID" && echo "true" || echo "false")
echo "  üîç V√©rification: gs://${CHECKPOINT_BUCKET}"
CHECKPOINT_EXISTS=$(check_bucket "$CHECKPOINT_BUCKET" "$PROJECT_ID" && echo "true" || echo "false")
echo "  üîç V√©rification: gs://${ARTIFACTS_BUCKET}"
ARTIFACTS_EXISTS=$(check_bucket "$ARTIFACTS_BUCKET" "$PROJECT_ID" && echo "true" || echo "false")

if [ "$DATA_EXISTS" = "true" ] && [ "$CHECKPOINT_EXISTS" = "true" ] && [ "$ARTIFACTS_EXISTS" = "true" ]; then
    echo "  ‚úÖ Tous les buckets existent"
    USE_EXISTING_BUCKETS="true"
else
    echo "  ‚ö†Ô∏è  Certains buckets n'existent pas ou ne sont pas accessibles:"
    [ "$DATA_EXISTS" = "true" ] && echo "    ‚úÖ gs://${DATA_BUCKET}" || echo "    ‚ùå gs://${DATA_BUCKET}"
    [ "$CHECKPOINT_EXISTS" = "true" ] && echo "    ‚úÖ gs://${CHECKPOINT_BUCKET}" || echo "    ‚ùå gs://${CHECKPOINT_BUCKET}"
    [ "$ARTIFACTS_EXISTS" = "true" ] && echo "    ‚úÖ gs://${ARTIFACTS_BUCKET}" || echo "    ‚ùå gs://${ARTIFACTS_BUCKET}"
    echo "  üí° Astuce: Si les buckets existent mais ne sont pas d√©tect√©s, v√©rifiez les permissions IAM"
    USE_EXISTING_BUCKETS="false"
fi

# D√©tection du dataset BigQuery
echo "üóÑÔ∏è  V√©rification du dataset BigQuery..."
if check_dataset "shopping_${ENVIRONMENT}" "$PROJECT_ID"; then
    echo "  ‚úÖ Dataset existe"
    USE_EXISTING_DATASET="true"
    
    # V√©rifier si la table orders existe
    echo "üìä V√©rification de la table orders..."
    if bq show --project_id="$PROJECT_ID" "${PROJECT_ID}:shopping_${ENVIRONMENT}.orders" >/dev/null 2>&1; then
        echo "  ‚úÖ Table orders existe - sera import√©e dans Terraform"
        TABLE_EXISTS="true"
    else
        echo "  ‚ùå Table orders n'existe pas"
        TABLE_EXISTS="false"
    fi
else
    echo "  ‚ùå Dataset n'existe pas"
    USE_EXISTING_DATASET="false"
    TABLE_EXISTS="false"
fi

echo ""
echo "üìù Mise √† jour de $TF_VARS_FILE..."

# Mettre √† jour le fichier terraform.tfvars
if [[ "$OSTYPE" == "darwin"* ]]; then
    # macOS
    sed -i '' "s/use_existing_dataset = .*/use_existing_dataset = $USE_EXISTING_DATASET/" "$TF_VARS_FILE"
    sed -i '' "s/use_existing_buckets = .*/use_existing_buckets = $USE_EXISTING_BUCKETS/" "$TF_VARS_FILE"
    sed -i '' "s/use_existing_service_accounts = .*/use_existing_service_accounts = $USE_EXISTING_SERVICE_ACCOUNTS/" "$TF_VARS_FILE"
else
    # Linux
    sed -i "s/use_existing_dataset = .*/use_existing_dataset = $USE_EXISTING_DATASET/" "$TF_VARS_FILE"
    sed -i "s/use_existing_buckets = .*/use_existing_buckets = $USE_EXISTING_BUCKETS/" "$TF_VARS_FILE"
    sed -i "s/use_existing_service_accounts = .*/use_existing_service_accounts = $USE_EXISTING_SERVICE_ACCOUNTS/" "$TF_VARS_FILE"
fi

echo ""
echo "‚úÖ Configuration mise √† jour automatiquement :"
echo "  use_existing_dataset = $USE_EXISTING_DATASET"
echo "  use_existing_buckets = $USE_EXISTING_BUCKETS"
echo "  use_existing_service_accounts = $USE_EXISTING_SERVICE_ACCOUNTS"
echo ""
echo "üöÄ Vous pouvez maintenant ex√©cuter terraform plan/apply"

