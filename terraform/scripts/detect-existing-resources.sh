#!/bin/bash
# Script bash pour d√©tecter automatiquement les ressources existantes
# et mettre √† jour les variables use_existing_* dans terraform.tfvars

set -e

PROJECT_ID="${1:-spark-streaming-483317}"
ENVIRONMENT="${2:-dev}"
TF_VARS_FILE="${3:-environments/dev/terraform.tfvars}"

echo "üîç D√©tection automatique des ressources existantes..."
echo "Projet: $PROJECT_ID"
echo "Environnement: $ENVIRONMENT"
echo ""

# Fonction pour v√©rifier si un Service Account existe
check_service_account() {
    local account_id=$1
    local project=$2
    gcloud iam service-accounts describe "${account_id}@${project}.iam.gserviceaccount.com" \
        --project="$project" >/dev/null 2>&1
    return $?
}

# Fonction pour v√©rifier si un bucket existe
check_bucket() {
    local bucket_name=$1
    local project=$2
    gsutil ls -p "$project" "gs://$bucket_name" >/dev/null 2>&1
    return $?
}

# Fonction pour v√©rifier si un dataset BigQuery existe
check_dataset() {
    local dataset_id=$1
    local project=$2
    bq show --project_id="$project" "${project}:${dataset_id}" >/dev/null 2>&1
    return $?
}

# D√©tection des Service Accounts
echo "üìã V√©rification des Service Accounts..."
if check_service_account "spark-dataproc-$ENVIRONMENT" "$PROJECT_ID" && \
   check_service_account "spark-consumer-$ENVIRONMENT" "$PROJECT_ID"; then
    echo "  ‚úÖ Service Accounts existent"
    USE_EXISTING_SERVICE_ACCOUNTS="true"
else
    echo "  ‚ùå Service Accounts n'existent pas"
    USE_EXISTING_SERVICE_ACCOUNTS="false"
fi

# D√©tection des buckets
echo "üì¶ V√©rification des buckets GCS..."
PIPELINE_NAME="spark-streaming-pipeline"
BUCKET_PREFIX="${PIPELINE_NAME}-${ENVIRONMENT}-$(echo $PROJECT_ID | tr '.' '-')"

if check_bucket "${BUCKET_PREFIX}-data" "$PROJECT_ID" && \
   check_bucket "${BUCKET_PREFIX}-checkpoints" "$PROJECT_ID" && \
   check_bucket "${BUCKET_PREFIX}-artifacts" "$PROJECT_ID"; then
    echo "  ‚úÖ Buckets existent"
    USE_EXISTING_BUCKETS="true"
else
    echo "  ‚ùå Buckets n'existent pas"
    USE_EXISTING_BUCKETS="false"
fi

# D√©tection du dataset BigQuery
echo "üóÑÔ∏è  V√©rification du dataset BigQuery..."
if check_dataset "shopping_${ENVIRONMENT}" "$PROJECT_ID"; then
    echo "  ‚úÖ Dataset existe"
    USE_EXISTING_DATASET="true"
    
    # V√©rifier si la table orders existe
    echo "üìä V√©rification de la table orders..."
    if bq show --project_id="$PROJECT_ID" "${PROJECT_ID}:shopping_${ENVIRONMENT}.orders" >/dev/null 2>&1; then
        echo "  ‚úÖ Table orders existe - sera import√©e dans Terraform"
        TABLE_EXISTS="true"
    else
        echo "  ‚ùå Table orders n'existe pas"
        TABLE_EXISTS="false"
    fi
else
    echo "  ‚ùå Dataset n'existe pas"
    USE_EXISTING_DATASET="false"
    TABLE_EXISTS="false"
fi

echo ""
echo "üìù Mise √† jour de $TF_VARS_FILE..."

# Mettre √† jour le fichier terraform.tfvars
if [[ "$OSTYPE" == "darwin"* ]]; then
    # macOS
    sed -i '' "s/use_existing_dataset = .*/use_existing_dataset = $USE_EXISTING_DATASET/" "$TF_VARS_FILE"
    sed -i '' "s/use_existing_buckets = .*/use_existing_buckets = $USE_EXISTING_BUCKETS/" "$TF_VARS_FILE"
    sed -i '' "s/use_existing_service_accounts = .*/use_existing_service_accounts = $USE_EXISTING_SERVICE_ACCOUNTS/" "$TF_VARS_FILE"
else
    # Linux
    sed -i "s/use_existing_dataset = .*/use_existing_dataset = $USE_EXISTING_DATASET/" "$TF_VARS_FILE"
    sed -i "s/use_existing_buckets = .*/use_existing_buckets = $USE_EXISTING_BUCKETS/" "$TF_VARS_FILE"
    sed -i "s/use_existing_service_accounts = .*/use_existing_service_accounts = $USE_EXISTING_SERVICE_ACCOUNTS/" "$TF_VARS_FILE"
fi

echo ""
echo "‚úÖ Configuration mise √† jour automatiquement :"
echo "  use_existing_dataset = $USE_EXISTING_DATASET"
echo "  use_existing_buckets = $USE_EXISTING_BUCKETS"
echo "  use_existing_service_accounts = $USE_EXISTING_SERVICE_ACCOUNTS"
echo ""
echo "üöÄ Vous pouvez maintenant ex√©cuter terraform plan/apply"

